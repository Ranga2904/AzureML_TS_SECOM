{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import and analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1          2          3       4      5         6       7    \\\n",
       "0     3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   97.6133  0.1242   \n",
       "1     3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0  102.3433  0.1247   \n",
       "2     2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   95.4878  0.1241   \n",
       "3     2988.72  2479.90  2199.0333   909.7926  1.3204  100.0  104.2367  0.1217   \n",
       "4     3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0  100.3967  0.1235   \n",
       "...       ...      ...        ...        ...     ...    ...       ...     ...   \n",
       "1562  2899.41  2464.36  2179.7333  3085.3781  1.4843  100.0   82.2467  0.1248   \n",
       "1563  3052.31  2522.55  2198.5667  1124.6595  0.8763  100.0   98.4689  0.1205   \n",
       "1564  2978.81  2379.78  2206.3000  1110.4967  0.8236  100.0   99.4122  0.1208   \n",
       "1565  2894.92  2532.01  2177.0333  1183.7287  1.5726  100.0   98.7978  0.1213   \n",
       "1566  2944.92  2450.76  2195.4444  2914.1792  1.5978  100.0   85.1011  0.1235   \n",
       "\n",
       "         8       9    ...     580       581     582     583     584      585  \\\n",
       "0     1.5005  0.0162  ...     NaN       NaN  0.5005  0.0118  0.0035   2.3630   \n",
       "1     1.4966 -0.0005  ...  0.0060  208.2045  0.5019  0.0223  0.0055   4.4447   \n",
       "2     1.4436  0.0041  ...  0.0148   82.8602  0.4958  0.0157  0.0039   3.1745   \n",
       "3     1.4882 -0.0124  ...  0.0044   73.8432  0.4990  0.0103  0.0025   2.0544   \n",
       "4     1.5031 -0.0031  ...     NaN       NaN  0.4800  0.4766  0.1045  99.3032   \n",
       "...      ...     ...  ...     ...       ...     ...     ...     ...      ...   \n",
       "1562  1.3424 -0.0045  ...  0.0047  203.1720  0.4988  0.0143  0.0039   2.8669   \n",
       "1563  1.4333 -0.0061  ...     NaN       NaN  0.4975  0.0131  0.0036   2.6238   \n",
       "1564     NaN     NaN  ...  0.0025   43.5231  0.4987  0.0153  0.0041   3.0590   \n",
       "1565  1.4622 -0.0072  ...  0.0075   93.4941  0.5004  0.0178  0.0038   3.5662   \n",
       "1566     NaN     NaN  ...  0.0045  137.7844  0.4987  0.0181  0.0040   3.6275   \n",
       "\n",
       "         586     587     588       589  \n",
       "0        NaN     NaN     NaN       NaN  \n",
       "1     0.0096  0.0201  0.0060  208.2045  \n",
       "2     0.0584  0.0484  0.0148   82.8602  \n",
       "3     0.0202  0.0149  0.0044   73.8432  \n",
       "4     0.0202  0.0149  0.0044   73.8432  \n",
       "...      ...     ...     ...       ...  \n",
       "1562  0.0068  0.0138  0.0047  203.1720  \n",
       "1563  0.0068  0.0138  0.0047  203.1720  \n",
       "1564  0.0197  0.0086  0.0025   43.5231  \n",
       "1565  0.0262  0.0245  0.0075   93.4941  \n",
       "1566  0.0117  0.0162  0.0045  137.7844  \n",
       "\n",
       "[1567 rows x 590 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('secom.data',sep=' ',header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('secom_labels.data',sep=' ',header=None)\n",
    "labels.columns = ['Class','Time']\n",
    "target = labels['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 1463, 1: 104})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       7\n",
       "2      14\n",
       "3      14\n",
       "4      14\n",
       "       ..\n",
       "585     1\n",
       "586     1\n",
       "587     1\n",
       "588     1\n",
       "589     1\n",
       "Length: 590, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "585    0\n",
       "586    0\n",
       "587    0\n",
       "588    0\n",
       "589    0\n",
       "Length: 590, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tpot in c:\\users\\ver2bj\\appdata\\roaming\\python\\python37\\site-packages (0.11.5)\n",
      "Requirement already satisfied: update-checker>=0.16 in c:\\users\\ver2bj\\appdata\\roaming\\python\\python37\\site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: deap>=1.2 in c:\\users\\ver2bj\\appdata\\roaming\\python\\python37\\site-packages (from tpot) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tpot) (0.22.2.post1)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\users\\ver2bj\\appdata\\roaming\\python\\python37\\site-packages (from tpot) (4.50.2)\n",
      "Requirement already satisfied: stopit>=1.1.1 in c:\\users\\ver2bj\\appdata\\roaming\\python\\python37\\site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tpot) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.3 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tpot) (1.18.4)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tpot) (0.14.1)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tpot) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->tpot) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->tpot) (1.12.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from update-checker>=0.16->tpot) (2.21.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ver2bj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.6.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install tpot\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.500500</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>97.934373</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>0.021458</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>99.670066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.496600</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>208.204500</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>208.204500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.443600</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>82.860200</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>82.860200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.488200</td>\n",
       "      <td>-0.012400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>73.843200</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>73.843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.503100</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>97.934373</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>73.843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.342400</td>\n",
       "      <td>-0.004500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>203.172000</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>203.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.433300</td>\n",
       "      <td>-0.006100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>97.934373</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>203.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>1.462862</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>43.523100</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>43.523100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.462200</td>\n",
       "      <td>-0.007200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>93.494100</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>93.494100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.462862</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>137.784400</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>137.784400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1          2          3       4      5         6       7    \\\n",
       "0     3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   97.6133  0.1242   \n",
       "1     3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0  102.3433  0.1247   \n",
       "2     2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   95.4878  0.1241   \n",
       "3     2988.72  2479.90  2199.0333   909.7926  1.3204  100.0  104.2367  0.1217   \n",
       "4     3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0  100.3967  0.1235   \n",
       "...       ...      ...        ...        ...     ...    ...       ...     ...   \n",
       "1562  2899.41  2464.36  2179.7333  3085.3781  1.4843  100.0   82.2467  0.1248   \n",
       "1563  3052.31  2522.55  2198.5667  1124.6595  0.8763  100.0   98.4689  0.1205   \n",
       "1564  2978.81  2379.78  2206.3000  1110.4967  0.8236  100.0   99.4122  0.1208   \n",
       "1565  2894.92  2532.01  2177.0333  1183.7287  1.5726  100.0   98.7978  0.1213   \n",
       "1566  2944.92  2450.76  2195.4444  2914.1792  1.5978  100.0   85.1011  0.1235   \n",
       "\n",
       "           8         9    ...       580         581     582     583     584  \\\n",
       "0     1.500500  0.016200  ...  0.005396   97.934373  0.5005  0.0118  0.0035   \n",
       "1     1.496600 -0.000500  ...  0.006000  208.204500  0.5019  0.0223  0.0055   \n",
       "2     1.443600  0.004100  ...  0.014800   82.860200  0.4958  0.0157  0.0039   \n",
       "3     1.488200 -0.012400  ...  0.004400   73.843200  0.4990  0.0103  0.0025   \n",
       "4     1.503100 -0.003100  ...  0.005396   97.934373  0.4800  0.4766  0.1045   \n",
       "...        ...       ...  ...       ...         ...     ...     ...     ...   \n",
       "1562  1.342400 -0.004500  ...  0.004700  203.172000  0.4988  0.0143  0.0039   \n",
       "1563  1.433300 -0.006100  ...  0.005396   97.934373  0.4975  0.0131  0.0036   \n",
       "1564  1.462862 -0.000841  ...  0.002500   43.523100  0.4987  0.0153  0.0041   \n",
       "1565  1.462200 -0.007200  ...  0.007500   93.494100  0.5004  0.0178  0.0038   \n",
       "1566  1.462862 -0.000841  ...  0.004500  137.784400  0.4987  0.0181  0.0040   \n",
       "\n",
       "          585       586       587       588         589  \n",
       "0      2.3630  0.021458  0.016475  0.005283   99.670066  \n",
       "1      4.4447  0.009600  0.020100  0.006000  208.204500  \n",
       "2      3.1745  0.058400  0.048400  0.014800   82.860200  \n",
       "3      2.0544  0.020200  0.014900  0.004400   73.843200  \n",
       "4     99.3032  0.020200  0.014900  0.004400   73.843200  \n",
       "...       ...       ...       ...       ...         ...  \n",
       "1562   2.8669  0.006800  0.013800  0.004700  203.172000  \n",
       "1563   2.6238  0.006800  0.013800  0.004700  203.172000  \n",
       "1564   3.0590  0.019700  0.008600  0.002500   43.523100  \n",
       "1565   3.5662  0.026200  0.024500  0.007500   93.494100  \n",
       "1566   3.6275  0.011700  0.016200  0.004500  137.784400  \n",
       "\n",
       "[1567 rows x 590 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "Version 0.11.5 of tpot is outdated. Version 0.11.7 was released Wednesday January 06, 2021.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Optimization Progress'), FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9106825452925345\n",
      "Generation 2 - Current best internal CV score: 0.9106825452925345\n",
      "Generation 3 - Current best internal CV score: 0.9106825452925345\n",
      "Generation 4 - Current best internal CV score: 0.9106825452925345\n",
      "Generation 5 - Current best internal CV score: 0.9106825452925345\n",
      "Best pipeline: ExtraTreesClassifier(ExtraTreesClassifier(RandomForestClassifier(input_matrix, bootstrap=False, criterion=gini, max_features=0.3, min_samples_leaf=17, min_samples_split=12, n_estimators=100), bootstrap=True, criterion=entropy, max_features=0.4, min_samples_leaf=19, min_samples_split=20, n_estimators=100), bootstrap=True, criterion=gini, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=7,shuffle=True)\n",
    "\n",
    "model = TPOTClassifier(generations=5, population_size=50, cv=cv, scoring='f1_weighted',verbosity=2, random_state=1, n_jobs=-1)\n",
    "# perform the search\n",
    "model.fit(data,target)\n",
    "# export the best model\n",
    "model.export('tpot_secom_best.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = train_test_split(data,target,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "# Average CV score on the training set was: 0.9106825452925345\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_features=0.3, min_samples_leaf=17, min_samples_split=12, n_estimators=100)),\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=True, criterion=\"entropy\", max_features=0.4, min_samples_leaf=19, min_samples_split=20, n_estimators=100)),\n",
    "    ExtraTreesClassifier(bootstrap=True, criterion=\"gini\", max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=100)\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 1)\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(results,testing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9381756041069386"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(results,testing_target,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[433,  26],\n",
       "       [ 10,   2]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(results,testing_target,labels=[-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Dissatisfactory TPOT performance - what about GridSearchCV that considers imbalance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "xgb = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24885183191396162"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = {'reg_alpha': [10], \n",
    "            'reg_lambda': [0.1],\n",
    "              'learning_rate': [0.001,0.01,0.1],\n",
    "            'scale_pos_weight':[40,60]}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=9,shuffle=True)\n",
    "\n",
    "gsXGB = GridSearchCV(xgb, xgb_params, cv = cv, scoring='f1', \n",
    "                     refit=True, n_jobs=5,return_train_score=True)\n",
    "gsXGB.fit(data,target)\n",
    "\n",
    "XGB_best = gsXGB.best_estimator_\n",
    "\n",
    "gsXGB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([21.08490181, 21.73392749, 21.43790221, 21.79892635, 22.37792516,\n",
       "        19.65493703, 19.04094005, 19.10092878, 18.85493827]),\n",
       " 'score_time': array([0.02199745, 0.01999784, 0.03099918, 0.0289979 , 0.02899981,\n",
       "        0.02400279, 0.02000308, 0.01600242, 0.0230031 ]),\n",
       " 'test_score': array([0.22641509, 0.04651163, 0.26415094, 0.21875   , 0.18867925,\n",
       "        0.31818182, 0.28571429, 0.14705882, 0.33333333]),\n",
       " 'train_score': array([0.44337349, 0.46616541, 0.47208122, 0.43867925, 0.52840909,\n",
       "        0.4972973 , 0.44660194, 0.44987775, 0.42592593])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(XGB_best,data,target,scoring='f1',cv=cv,n_jobs=5,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=10,\n",
       "              reg_lambda=0.1, scale_pos_weight=40, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_best.fit(training_features, training_target)\n",
    "results = XGB_best.predict(testing_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(results,testing_target,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(results,testing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8774678111587982"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(results,testing_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) What about GridSearchCV that considers imbalance that incorporates Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [  5  13  42  49  52  69  97 141 149 178 179 186 189 190 191 192 193 194\n",
      " 226 229 230 231 232 233 234 235 236 237 240 241 242 243 256 257 258 259\n",
      " 260 261 262 263 264 265 266 276 284 313 314 315 322 325 326 327 328 329\n",
      " 330 364 369 370 371 372 373 374 375 378 379 380 381 394 395 396 397 398\n",
      " 399 400 401 402 403 404 414 422 449 450 451 458 461 462 463 464 465 466\n",
      " 481 498 501 502 503 504 505 506 507 508 509 512 513 514 515 528 529 530\n",
      " 531 532 533 534 535 536 537 538] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "# configure to select all features\n",
    "fs = SelectKBest(score_func=f_classif, k=40)\n",
    "# learn relationship from training data\n",
    "fs.fit(training_features,training_target)\n",
    "# transform train input data\n",
    "X_train_fs = fs.transform(training_features)\n",
    "# # transform test input data\n",
    "# X_test_fs = fs.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "# for i in range(len(fs.scores_)):\n",
    "#     print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, X_test):\n",
    "\t# configure to select a subset of features\n",
    "\tfs = SelectKBest(score_func=f_classif, k=40)\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(X_train, y_train)\n",
    "\t# transform train input data\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\t# transform test input data\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [  5  13  42  49  52  69  97 141 149 178 179 186 189 190 191 192 193 194\n",
      " 226 229 230 231 232 233 234 235 236 237 240 241 242 243 256 257 258 259\n",
      " 260 261 262 263 264 265 266 276 284 313 314 315 322 325 326 327 328 329\n",
      " 330 364 369 370 371 372 373 374 375 378 379 380 381 394 395 396 397 398\n",
      " 399 400 401 402 403 404 414 422 449 450 451 458 461 462 463 464 465 466\n",
      " 481 498 501 502 503 504 505 506 507 508 509 512 513 514 515 528 529 530\n",
      " 531 532 533 534 535 536 537 538] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "X_train_fs, X_test_fs, fs = select_features(training_features, training_target, testing_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90682217339955"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = {'reg_alpha': [0.1,1,10], \n",
    "            'reg_lambda': [0.1,1,10],\n",
    "            'scale_pos_weight':[7,20,40]}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=9,shuffle=True)\n",
    "\n",
    "gsXGB = GridSearchCV(xgb, xgb_params, cv = cv, scoring='f1_weighted', \n",
    "                     refit=True, n_jobs=5,return_train_score=True)\n",
    "gsXGB.fit(X_train_fs, training_target)\n",
    "\n",
    "XGB_best_feat_sel = gsXGB.best_estimator_\n",
    "\n",
    "gsXGB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.915685455156862"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = XGB_best_feat_sel.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(testing_target, yhat,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [  5  13  42  49  52  69  97 141 149 178 179 186 189 190 191 192 193 194\n",
      " 226 229 230 231 232 233 234 235 236 237 240 241 242 243 256 257 258 259\n",
      " 260 261 262 263 264 265 266 276 284 313 314 315 322 325 326 327 328 329\n",
      " 330 364 369 370 371 372 373 374 375 378 379 380 381 394 395 396 397 398\n",
      " 399 400 401 402 403 404 414 422 449 450 451 458 461 462 463 464 465 466\n",
      " 481 498 501 502 503 504 505 506 507 508 509 512 513 514 515 528 529 530\n",
      " 531 532 533 534 535 536 537 538] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\ver2bj\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9140160341962423"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_feat(X_train, y_train, X_test):\n",
    "\t# configure to select a subset of features\n",
    "\tfs = SelectKBest(score_func=f_classif, k=4)\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(X_train, y_train)\n",
    "\t# transform train input data\n",
    "\tX_train_fs = fs.transform(X_train)\n",
    "\t# transform test input data\n",
    "\tX_test_fs = fs.transform(X_test)\n",
    "\treturn X_train_fs, X_test_fs, fs\n",
    "\n",
    "X_train_fs, X_test_fs, fs = select_feat(training_features, training_target, testing_features)\n",
    "\n",
    "xgb_params = {'reg_alpha': [0.1,1,10], \n",
    "            'reg_lambda': [0.1,1,10],\n",
    "            'scale_pos_weight':[7,20,40]}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=9,shuffle=True)\n",
    "\n",
    "gsXGB = GridSearchCV(xgb, xgb_params, cv = cv, scoring='f1_weighted', \n",
    "                     refit=True, n_jobs=5,return_train_score=True)\n",
    "gsXGB.fit(X_train_fs, training_target)\n",
    "\n",
    "XGB_best_feats = gsXGB.best_estimator_\n",
    "\n",
    "gsXGB.best_score_\n",
    "\n",
    "yhat = XGB_best_feats.predict(X_test_fs)\n",
    "# evaluate predictions\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(testing_target, yhat,average=\"weighted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
